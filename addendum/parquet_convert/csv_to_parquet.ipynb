{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get update -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install -y p7zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso los datos están disponibles en un repositorio git. Se pueden descargar también de la Web, pero se van actualizando. Los descargamos del repositorio git para que todos tengáis los mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/dsevilla/bd2-data/raw/main/es.stackoverflow/es.stackoverflow.7z.001\n",
    "!wget https://github.com/dsevilla/bd2-data/raw/main/es.stackoverflow/es.stackoverflow.7z.002\n",
    "!wget https://github.com/dsevilla/bd2-data/raw/main/es.stackoverflow/es.stackoverflow.7z.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh es.stackoverflow.7z*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!7zr x es.stackoverflow.7z.001\n",
    "!rm es.stackoverflow.7z.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh *.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspección y procesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos inspeccionar los ficheros `.xml` para ver su contenido. Son XML, sí, pero ¿con qué formato?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque se puede procesar el formato XML, lo que podemos ver es que cada entrada es exactamente una línea que comienza por \"`<row`\", y que contiene un conjunto de atributos en formato \"`atributo=\"valor\"`\". Si lo comprobamos, incluso no existirá ninguna comilla doble **dentro** de otra comilla doble, así que podemos extraer esos pares de forma facil.\n",
    "\n",
    "La siguiente función procesa el fichero XML línea a línea. Primero separa la parte inicial \"`<row`\", y después procesa cada par clave/valor. Lo único que hace es construir el conjunto de atributos que hay en todas las entradas. Como vimos, cada fila contenía atributos diferentes. Queremos obtenerlos todos.\n",
    "\n",
    "La función, en vez de retornar una lista, que ocuparía mucha memoria, retorna un generador, que es una lista (de pares clave-valor, un diccionario) que se va generando a medida que se recorre. Por eso utiliza la construcción `yield` de Python. Esto hace que la función se detenga, y cuando se le pide el siguiente elemento, continúa desde donde se quedó (corrutina)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Iterator\n",
    "\n",
    "def generate_elements_from_lines(filename: str) -> Iterator[dict[str, str]]:\n",
    "\n",
    "  def get_attrs(line: str) -> dict[str, str]:\n",
    "    (_, attrs) = line.split(\"<row \", 2)\n",
    "    return {m.group(1): m.group(2)\n",
    "              for m in re.finditer(r\"(\\w*?)=\\\"(.*?)\\\"\", attrs)}\n",
    "\n",
    "  with open(filename, \"r\") as f:\n",
    "    for line in f:\n",
    "      if \"<row\" in line:\n",
    "        yield get_attrs(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que extraer el conjunto de atributos para saber qué columnas tendrá nuestra tabla/CSV o archivo JSON. Recuérdese que las dos primeras filas del archivo XML tenían diferentes atributos. ¿Cómo se haría esto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "\n",
    "def get_all_attrs(iterator: Iterator[dict[str,str]]) -> set[str]:\n",
    "  all_attrs: set[str] = set()\n",
    "  for row in iterator:\n",
    "    all_attrs.update(row.keys())\n",
    "  return all_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de atributos es pues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_attrs_posts = get_all_attrs(generate_elements_from_lines(\"Posts.xml\"))\n",
    "all_attrs_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como sabemos que el atributo `Id` va a ser la clave primaria, lo ponemos al principio. Además, generamos una lista, no un conjunto, para que el orden sea conocido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_as_first_attribute(all_attrs: set[str], id_name: str) -> list[str]:\n",
    "  all_attrs.remove(id_name)\n",
    "  return [id_name] + list(all_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_attrs_posts = id_as_first_attribute(all_attrs_posts, 'Id')\n",
    "all_attrs_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escritura del formato CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El formato CSV está especificado en el estándar RFC 4180. https://www.ietf.org/rfc/rfc4180.txt. En general se puede utilizar la biblioteca `csv` de Python 3 y vamos a exportar una línea de cabecera con todos los campos. https://docs.python.org/3/library/csv.html.\n",
    "\n",
    "Tendremos en cuenta que todas las filas tienen que tener las mismas columnas y en el mismo orden dado por `all_attrs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_csv(destfile: str, all_attrs: list[str], iterator: Iterator[dict[str,str]]) -> None:\n",
    "  with open(destfile, 'w') as wf:\n",
    "    cw = csv.writer(wf)\n",
    "\n",
    "    # Escribir la línea de cabecera\n",
    "    cw.writerow(all_attrs)\n",
    "\n",
    "    # Recorrer el iterador\n",
    "    for row in iterator:\n",
    "      row_to_write = [row.get(att, '') for att in all_attrs]\n",
    "      cw.writerow(row_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv('Posts.csv', all_attrs_posts, generate_elements_from_lines('Posts.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the df dataframe to parquet file\n",
    "df = pd.read_csv('Posts.csv', encoding='utf-8', header=0,\n",
    "                 dtype={'Id': 'Int64', 'PostTypeId': 'Int64', 'AcceptedAnswerId': 'Int64', 'ParentId': 'Int64',\n",
    "                        'Score': 'Int64', 'ViewCount': 'Int64',\n",
    "                        'Body': pd.StringDtype(), 'OwnerUserId': 'Int64', 'OwnerDisplayName': pd.StringDtype(),\n",
    "                        'LastEditorUserId': 'Int64', 'LastEditorDisplayName': pd.StringDtype(),\n",
    "                        'Title': pd.StringDtype(), 'Tags': pd.StringDtype(), 'AnswerCount': 'Int64',\n",
    "                        'CommentCount': 'Int64', 'FavoriteCount': 'Int64',\n",
    "                        'ContentLicense': pd.StringDtype()},\n",
    "                 parse_dates=['CreationDate','LastEditDate','LastActivityDate','ClosedDate','CommunityOwnedDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('Posts.parquet', compression='snappy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_attrs_votes = get_all_attrs(generate_elements_from_lines(\"Votes.xml\"))\n",
    "all_attrs_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_attrs_votes = id_as_first_attribute(all_attrs_votes, 'Id')\n",
    "all_attrs_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv('Votes.csv', all_attrs_votes, generate_elements_from_lines('Votes.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the df dataframe to parquet file\n",
    "df = pd.read_csv('Votes.csv', encoding='utf-8', header=0,\n",
    "                 dtype={'Id': 'Int64', 'VoteTypeId' : 'Int64', 'BountyAmount' : 'Int64', 'PostId': 'Int64', 'UserId' : 'Int64' },\n",
    "                 parse_dates=['CreationDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('Votes.parquet', compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_attrs_votes = get_all_attrs(generate_elements_from_lines(\"Votes.xml\"))\n",
    "all_attrs_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_attrs_votes = id_as_first_attribute(all_attrs_votes, 'Id')\n",
    "all_attrs_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv('Votes.csv', all_attrs_votes, generate_elements_from_lines('Votes.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the df dataframe to parquet file\n",
    "df = pd.read_csv('Votes.csv', encoding='utf-8', header=0,\n",
    "                 dtype={'Id': 'Int64', 'VoteTypeId' : 'Int64', 'BountyAmount' : 'Int64', 'PostId': 'Int64', 'UserId' : 'Int64' },\n",
    "                 parse_dates=['CreationDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('Votes.parquet', compression='snappy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
