{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a Jupyter Notebook, Pandas, Matplotlib, etc.\n",
    "\n",
    "En esta hoja introduciremos la forma de trabajar con Jupyter Notebook, instalado a través de la imagen docker `jupyter/scipy-notebook`. Veremos cómo los distintos elementos de las librerías de Python interactúan con el notebook para mostrar imágenes, gráficos, etc. También, en las siguientes sesiones los usaremos para acceder a conexiones SQL y a bases de datos NoSQL.\n",
    "\n",
    "Enlaces a otros tutoriales introductorios (que también se centran en tratamiento de datos para Big Data): [1](https://github.com/CharlestonDataScience/PythonNotebooks/blob/master/notebooks/tutorial_01/pandas_tutorial.ipynb) y [2](https://github.com/phelps-sg/python-bigdata/blob/master/src/main/ipynb/pandas.ipynb), entre otros muchos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Pequeña introducción a Docker, Docker-Compose y Jupyter Notebook\n",
    "\n",
    "_Docker_ es un gestor de contenedores. Permite instalar paquetes pre-instalados de las utilidades que vamos a usar en este curso. En las máquinas del laboratorio está instalado el paquete _Docker_ de Jupyter Notebook que usaremos. Para listar los contenedores _docker_ disponibles en una máquina podemos ejecutar `docker images`:\n",
    "\n",
    "    $ docker images\n",
    "    REPOSITORY                     TAG                 IMAGE ID            CREATED             SIZE\n",
    "    jupyter/scipy-notebook         latest              fd9cad0aeeeb        2 months ago        6.57GB\n",
    "    neo4j                          latest              9481a852963b        2 months ago        173MB\n",
    "    mongo                          latest              57c67caab3d8        2 months ago        359MB\n",
    "\n",
    "_Docker_ ofrece también `docker-compose`, una utilidad que permite conectar entre sí varios contenedores ofreciendo servicios. `docker-compose` también descargará automáticamente los contenedores necesarios. En cada directorio de cada sesión de prácticas existirá un fichero `docker-compose.yml`, que incluye la configuración para ejecutar el _Notebook_ y los otros contenedores necesarios (por ejemplo otras bases de datos).\n",
    "\n",
    "Para las prácticas vamos a usar la imagen `jupyter/scipy-notebook`. La información de cómo usar este contenedor se puede obtener [aquí](https://hub.docker.com/r/jupyter/scipy-notebook/).\n",
    "\n",
    "### Instalación de Docker en Windows\n",
    "\n",
    "Si se quiere utilizar Docker desde Windows, se puede hacer igualmente. Existen unas instrucciones para usar [Docker en Windows](https://docs.docker.com/docker-for-windows/). Una vez instalado, habría que instalar la imagen que usaremos con la misma orden `docker pull jupyter/all-spark-notebook`.\n",
    "\n",
    "### Instalación de Docker en la máquina virtual\n",
    "\n",
    "En el máster se proporciona una máquina virtual. En el caso de que no tenga instalado docker, se puede instalar con las instrucciones:\n",
    "\n",
    "    $ sudo apt-get install docker docker-compose\n",
    "    $ sudo systemctl enable docker\n",
    "    $ sudo systemctl start docker\n",
    "\n",
    "\n",
    "### Descarga del código de prácticas\n",
    "\n",
    "Existen varias formas de traer el código de prácticas al contenedor. La más sencilla es ejecutar el siguiente código:\n",
    "    \n",
    "    $ git clone https://github.com/dsevilla/bdge.git\n",
    "    \n",
    "Esto creará el directorio `bdge` con todo el código de las prácticas. Dentro de cada subdirectorio (por ejemplo en este caso `intro`), habrá un fichero `docker-compose.yml`, que sirve para ejecutar y conectar los contenedores necesarios para cada parte de la práctica. Así pues:\n",
    "\n",
    "    $ git clone https://github.com/dsevilla/bdge.git\n",
    "    $ cd bdge/intro\n",
    "    $ docker-compose up\n",
    "    Creating network \"intro_default\" with the default driver\n",
    "    Creating intro_notebook_1 ... done\n",
    "    Attaching to intro_notebook_1\n",
    "    notebook_1  | Execute the command\n",
    "    notebook_1  | [I 10:32:05.350 NotebookApp] Writing notebook server cookie secret to ...\n",
    "    notebook_1  | [I 10:32:05.578 NotebookApp] Serving notebooks from local directory: /home/jovyan\n",
    "    notebook_1  | [I 10:32:05.578 NotebookApp] 0 active kernels \n",
    "    notebook_1  | [I 10:32:05.578 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
    "    notebook_1  |     to login:\n",
    "    notebook_1  |         http://localhost:8888/\n",
    "\n",
    "Accediendo a la IP http://localhost:8888/ ó http://127.0.0.1:8888/ se accede al _Notebook_, y el directorio actual (`intro`) aparece disponible en la lista de directorios.\n",
    "\n",
    "\n",
    "**Se aconseja guardar el Notebook con otro nombre (File->Rename...) para evitar problemas con las actualizaciones posteriores del repositorio con `git`.**\n",
    "\n",
    "Para parar el contenedor, se puede ejecutar:\n",
    "\n",
    "    $ docker-compose stop\n",
    "    $ docker-compose rm\n",
    "\n",
    "(Si no se realiza el `rm`, `docker-compose up` volverá a lanzar el contenedor anteriormente parado).\n",
    "\n",
    "### Ejecución del Jupyter Notebook de forma aislada\n",
    "\n",
    "El Notebook también se puede ejecutar independientemente. Para ejecutar una sesión de Jupyter Notebook hay que escribir:\n",
    "\n",
    "    $ docker run -it --rm -p 8888:8888 jupyter/scipy-notebook\n",
    "    [I 23:39:02.615 NotebookApp] Writing notebook server cookie secret to ...\n",
    "    [W 23:39:02.712 NotebookApp] WARNING: The notebook server is listening ...\n",
    "    [I 23:39:02.877 NotebookApp] Use Control-C to stop this server and shut down all kernels ...\n",
    "    \n",
    "    Copy/paste this URL into your browser when you connect for the first time,\n",
    "    to login with a token:\n",
    "        http://localhost:8888/?token=<TOKEN>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebook\n",
    "\n",
    "Los *Notebooks* contienen una mezcla de texto y código, y se pueden ir ejecutando paso a paso. Al pulsar Ctrl+Intro en una celda, se ejecuta el código de la celda y se muestra el la siguiente celda. Al pulsar Shift+Intro se ejecuta la celda actual y pasa automáticamente a la siguiente.\n",
    "\n",
    "Existen también \"magics\", que sirven para obtener información de la hoja, o ejecutar comandos especiales. Por ejemplo, órdenes de shell, como en la siguiente celda. Hay varios tutoriales Online. Por ejemplo: [Tutorial](https://github.com/esc/scipy2013-tutorial-numpy-ipython/blob/master/ipython.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uname -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación mostramos los paquetes que usaremos regularmente para tratar datos, `pandas`, `numpy`, `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo siguiente hace que los gráficos se muestren inline. Para figuras pequeñas se puede utilizar unas figuras interactivas que permiten zoom, usando `%maplotlib nbagg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy\n",
    "\n",
    "Numpy es una de las librerías más utilizadas en Python, y ofrece un interfaz sencillo para operaciones eficientes con números, _arrays_ y matrices. Numpy se utilizará de apoyo muchas veces que haya que hacer procesamiento local de datos recogidos de una base de datos, o como preparación para la graficación de datos. En la celda siguiente se muestra un vídeo introductorio, y también se puede acceder a tutoriales online: [Tutorial](https://github.com/esc/scipy2013-tutorial-numpy-ipython/blob/master/operations.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('o8fmjaW9a0A') # Yes, it can also embed youtube videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy permite generar y procesar arrays de datos de forma muy eficiente. A continuación se muestran algunos ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([4,5,6])\n",
    "print(a.shape)\n",
    "print(a[0])\n",
    "a[0] = 9\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(1,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También arrays multidimensionales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((2,2))\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.random((2,2))\n",
    "print (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random((2,2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (a >= .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (a[a >= .5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué usar Numpy? `%%capture` captura la salida de la ejecución de la celda en la variable dada como parámetro. Después se puede imprimir. `%timeit` se utiliza para ejecutar varias veces una instrucción y calcular un promedio de su duración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture timeit_output\n",
    "\n",
    "%timeit l1 = range(1,1000)\n",
    "\n",
    "%timeit l2 = np.arange(1,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(timeit_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.array([[1,2],[3,4]])\n",
    "\n",
    "print (np.sum(x))  # Compute sum of all elements; prints \"10\"\n",
    "print (np.sum(x, axis=0))  # Compute sum of each column; prints \"[4 6]\"\n",
    "print (np.sum(x, axis=1))  # Compute sum of each row; prints \"[3 7]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib\n",
    "\n",
    "Matplotlib permite generar gráficos de forma sencilla. Lo veremos aquí primero conectado sólo con `Numpy` y después conectado con `Pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 3 * np.pi, 0.1)\n",
    "y = np.sin(x)\n",
    "plt.subplot()\n",
    "# Plot the points using matplotlib\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.plot(range(12))\n",
    "plt.subplot(212, facecolor='y')\n",
    "plt.plot(range(100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the x and y coordinates for points on sine and cosine curves\n",
    "x = np.arange(0, 3 * np.pi, 0.1)\n",
    "y_sin = np.sin(x)\n",
    "y_cos = np.cos(x)\n",
    "\n",
    "# Plot the points using matplotlib\n",
    "plt.plot(x, y_sin)\n",
    "plt.plot(x, y_cos)\n",
    "plt.xlabel('x axis label')\n",
    "plt.ylabel('y axis label')\n",
    "plt.title('Sine and Cosine')\n",
    "plt.legend(['Sine', 'Cosine'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Tutoriales: [1](http://pandas.pydata.org/pandas-docs/version/0.18.1/tutorials.html), [2](https://dev.socrata.com/blog/2016/02/01/pandas-and-jupyter-notebook.html), [3](http://nikgrozev.com/2015/12/27/pandas-in-jupyter-quickstart-and-useful-snippets/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas permite gestionar conjuntos de datos n-dimensionales de diferentes formas, y también conectarlo con matplotlib para hacer gráficas.\n",
    "\n",
    "Los conceptos principales de Pandas son los `Dataframe`s y las `Series`. La diferencia entre ambas es que la serie guarda sólo una serie (una columna o una fila, depende de como se quiera interpretar), mientras que un Dataframe guarda estructuras multidimensaionales agregando series.\n",
    "\n",
    "Ambas tienen una \"columna fantasma\", que sirve de índice, y que se puede acceder con `d.index` (tanto si `d` es una serie o un dataframe). Si no se especifica un índice, se le añade uno virtual numerando las filas desde cero. Además, los índices pueden ser multidimensionales (por ejemplo, tener un índice por mes y dentro uno por dia de la semana)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ts.cumsum()\n",
    "ts.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list('ABCD'))\n",
    "\n",
    "df = df.cumsum()\n",
    "\n",
    "df.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede hacer plot también de una columna contra otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(np.random.randn(1000, 2), columns=['B', 'C']).cumsum()\n",
    "df3['A'] = pd.Series(list(range(len(df3))))\n",
    "df3.plot(x='A', y='B');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valores incompletos. Si no se establecen, se pone a `NaN` (_not a number_). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'one' : pd.Series([1., 2., 3.], index=['a', 'b', 'c']),\n",
    "     'two' : pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fillna()` permite cambiar el valor de los datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(d, index=['d', 'b', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(d, index=['d', 'b', 'a'], columns=['two', 'three'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer ejemplo completo carga desde el fichero `swift-question-dates.txt.gz` las fechas de las preguntas en Stackoverflow que contienen el tag \"swift\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!zcat swift-question-dates.txt.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `read_csv` es capaz de leer cualquier fichero CSV y lo convierte en un \"Dataframe\", una estructura de tabla que guarda también los nombres y los tipos de las columnas, así como un índice por el que se identificarán las tablas. En este caso no se especifica ninguna columna como índice, por lo que se crea un índice automático numerado empezando desde 0. Se puede ver en la siguiente celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('swift-question-dates.txt.gz',header=None,names=['date'],compression='gzip',parse_dates=['date'],index_col='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la fecha, extraer sólo la fecha (no la hora, que no nos interesa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df.index.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos una columna de todo \"1\" para especificar que cada pregunta cuenta como 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Count'] = 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A los Dataframe de Pandas también se les puede aplicar operaciones de agregación, como `groupby` o `sum`. Finalmente, la funcion `plot()` permite mostrar los datos en un gráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accum = df.groupby(df.index).sum()\n",
    "accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los 30 primeros registros que tengan un número de preguntas mayor que 20 por día.\n",
    "accum = accum[accum.Count > 20][:30]\n",
    "accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accum[accum.Count > 30][:30].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwiki = pd.read_html('https://en.wikipedia.org/wiki/Swift_(programming_language)',attrs={'class': 'infobox vevent'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwiki[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstdate = dfwiki[0][1][4]\n",
    "firstdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "m = re.search('\\d{4}-\\d{2}-\\d{2}',firstdate)\n",
    "assert m.group(0) == accum.index[0].isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar municipios y mostrarlos en el mapa\n",
    "df = pd.read_csv('municipios-españa-2017.csv.gz',header=0,compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0].NOMBRE_ACTUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[:,'NOMBRE_ACTUAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.PROVINCIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df.PROVINCIA == 'A Coruña']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mula = df[df.NOMBRE_ACTUAL == 'Mula'].iloc[0]\n",
    "mula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mula_lat,mula_lon) = (mula.LATITUD_ETRS89, mula.LONGITUD_ETRS89)\n",
    "(mula_lat,mula_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paquete `folium` permite generar mapas de posiciones. El siguiente ejemplo centra un mapa en Madrid y pone un marcador con su nombre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "map = folium.Map(location=[mula_lat, mula_lon],zoom_start=8)\n",
    "folium.Marker(location = [mula_lat, mula_lon], popup=mula.NOMBRE_ACTUAL).add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "Mostrar con `folium` marcadores para cada pueblo de A Coruña y Murcia. Se pueden usar las funciones `itertuples()` o `iterrows()` de un `Dataframe` para recorrer los elementos del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
