{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la8Wi7C_0gyZ"
      },
      "source": [
        "# Introducción a Jupyter Notebook, Pandas, Matplotlib, etc.\n",
        "\n",
        "En esta hoja introduciremos la forma de trabajar con Jupyter Notebook/Google Colab. Veremos cómo los distintos elementos de las librerías de Python interactúan con el notebook para mostrar imágenes, gráficos, etc. También, en las siguientes sesiones los usaremos para acceder a conexiones SQL y a bases de datos NoSQL.\n",
        "\n",
        "Enlaces a otros tutoriales introductorios (que también se centran en tratamiento de datos para Big Data): [1](https://github.com/CharlestonDataScience/PythonNotebooks/blob/master/notebooks/tutorial_01/pandas_tutorial.ipynb) y [2](https://github.com/phelps-sg/python-bigdata/blob/master/src/main/ipynb/pandas.ipynb), entre otros muchos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVwChyC10gyl"
      },
      "source": [
        "## Jupyter/Colab Notebook\n",
        "\n",
        "Los *Notebooks* contienen una mezcla de texto y código, y se pueden ir ejecutando paso a paso. En general utilizaremos el lenguaje Python en su versión 3, así que las hojas son en realidad un programa Python que se puede ejecutar en orden, junto con imágenes y texto explicativo adjunto.\n",
        "\n",
        "Al pulsar Ctrl+Intro en una celda, se ejecuta el código de la celda y se muestra el la siguiente celda. Al pulsar Shift+Intro se ejecuta la celda actual y pasa automáticamente a la siguiente.\n",
        "\n",
        "Existen también \"magics\", que sirven para obtener información de la hoja, o ejecutar comandos especiales. Por ejemplo, órdenes de shell, como en la siguiente celda. Hay varios tutoriales Online. Por ejemplo: [Tutorial](https://github.com/esc/scipy2013-tutorial-numpy-ipython/blob/master/ipython.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQP8GpuC0gyr"
      },
      "outputs": [],
      "source": [
        "!uname -a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16n5PqCp0gzM"
      },
      "outputs": [],
      "source": [
        "%lsmagic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUKmEEKuBO6x"
      },
      "source": [
        "Actualizamos los paquetes necesarios. En general esto no hace falta en Google Colab, pero sí en Jupyter Notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbeHGejDBO6x"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40eR4mfVBO6y"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install -y p7zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSBkYju1BO6z"
      },
      "outputs": [],
      "source": [
        "RunningInCOLAB = 'google.colab' in str(get_ipython()) if hasattr(__builtins__,'__IPYTHON__') else False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs7khh660gze"
      },
      "source": [
        "A continuación mostramos los paquetes que usaremos regularmente para tratar datos, `pandas`, `numpy`, `matplotlib`. Al ser un programa en Python, se pueden importar paquetes que seguirán siendo válidos hasta el final del _notebook_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm7Lxq3b0gzi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnHsIiOJ0gzx"
      },
      "source": [
        "Lo siguiente hace que los gráficos se muestren inline. Para figuras pequeñas se puede utilizar unas figuras interactivas que permiten zoom, usando `%maplotlib nbagg`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54LyaN9h0gz2"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "matplotlib.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbNgEEmW0g0F"
      },
      "source": [
        "## Numpy\n",
        "\n",
        "Numpy es una de las librerías más utilizadas en Python, y ofrece un interfaz sencillo para operaciones eficientes con números, _arrays_ y matrices. Numpy se utilizará de apoyo muchas veces que haya que hacer procesamiento local de datos recogidos de una base de datos, o como preparación para la graficación de datos. En la celda siguiente se muestra un vídeo introductorio, y también se puede acceder a tutoriales online: [Tutorial](https://github.com/esc/scipy2013-tutorial-numpy-ipython/blob/master/operations.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tqi4z-h0g0J"
      },
      "outputs": [],
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('o8fmjaW9a0A') # Yes, it can also embed youtube videos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAssJtAv0g0c"
      },
      "source": [
        "Numpy permite generar y procesar arrays de datos de forma muy eficiente. A continuación se muestran algunos ejemplos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTIZsrqm0g0e"
      },
      "outputs": [],
      "source": [
        "a = np.array([4,5,6])\n",
        "print(a.shape)\n",
        "print(a[0])\n",
        "a[0] = 9\n",
        "print (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqwxBBDR0g0q"
      },
      "outputs": [],
      "source": [
        "np.arange(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juBoOUXv0g03"
      },
      "outputs": [],
      "source": [
        "np.arange(1,20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur7PeiO40g1H"
      },
      "source": [
        "También arrays multidimensionales:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAxRAAUn0g1K"
      },
      "outputs": [],
      "source": [
        "a = np.zeros((2,2))\n",
        "print (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrvObDnf0g1Y"
      },
      "outputs": [],
      "source": [
        "a.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXEAG5cV0g1l"
      },
      "outputs": [],
      "source": [
        "a.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTpwAgyj0g14"
      },
      "outputs": [],
      "source": [
        "b = np.random.random((2,2))\n",
        "print (b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "webIPAma0g2F"
      },
      "outputs": [],
      "source": [
        "a = np.random.random((2,2))\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o0QZDMy0g2T"
      },
      "source": [
        "Se pueden aplicar funciones sobre todo el array o matriz, y el resultado será una matriz idéntica con el operador aplicado. Similar a lo que ocurre con la operación `map` de algunos lenguajes de programación (incluído Python):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFpNqjd-0g2V"
      },
      "outputs": [],
      "source": [
        "print (a >= .5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09xWrIqZ0g2u"
      },
      "source": [
        "También se pueden _filtrar_ los elementos de un array o matriz que cumplan una condición. Para eso se utiliza el operador de indización (`[]`) con una expresión booleana."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lf8zXQ6r0g2w"
      },
      "outputs": [],
      "source": [
        "print (a[a >= .5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LntLnGSC0g29"
      },
      "source": [
        "¿Por qué usar Numpy?\n",
        "\n",
        "`%%capture` captura la salida de la ejecución de la celda en la variable dada como parámetro. Después se puede imprimir.\n",
        "\n",
        "`%timeit` se utiliza para ejecutar varias veces una instrucción y calcular un promedio de su duración."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUM4mNqc0g3A"
      },
      "outputs": [],
      "source": [
        "%%capture timeit_output\n",
        "\n",
        "%timeit l1 = range(1,1000)\n",
        "\n",
        "%timeit l2 = np.arange(1,1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUXOSmWP0g3M"
      },
      "outputs": [],
      "source": [
        "print(timeit_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZJKGRoj0g3Z",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "x = np.array([[1,2],[3,4]])\n",
        "\n",
        "print (np.sum(x))  # Compute sum of all elements; prints \"10\"\n",
        "print (np.sum(x, axis=0))  # Compute sum of each column; prints \"[4 6]\"\n",
        "print (np.sum(x, axis=1))  # Compute sum of each row; prints \"[3 7]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pLMfeT10g3j"
      },
      "outputs": [],
      "source": [
        "x * 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyW6o5hI0g4C"
      },
      "outputs": [],
      "source": [
        "x ** 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uig7nF20g4N"
      },
      "source": [
        "`numpy` tiene infinidad de funciones, por lo que sería interesante darse una vuelta por su documentación: https://docs.scipy.org/doc/."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQV9Ttle0g4P"
      },
      "source": [
        "## Matplotlib\n",
        "\n",
        "Matplotlib permite generar gráficos de forma sencilla. Lo veremos aquí primero conectado sólo con `Numpy` y después conectado con `Pandas`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5kz-KFL0g4R"
      },
      "outputs": [],
      "source": [
        "x = np.arange(0, 3 * np.pi, 0.1)\n",
        "y = np.sin(x)\n",
        "plt.subplot()\n",
        "# Plot the points using matplotlib\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgdTh4Y60g4e"
      },
      "outputs": [],
      "source": [
        "plt.subplot(211)\n",
        "plt.plot(range(12))\n",
        "plt.subplot(212, facecolor='y')\n",
        "plt.plot(range(100))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_PgM4a20g4q"
      },
      "outputs": [],
      "source": [
        "# Compute the x and y coordinates for points on sine and cosine curves\n",
        "x = np.arange(0, 3 * np.pi, 0.1)\n",
        "y_sin = np.sin(x)\n",
        "y_cos = np.cos(x)\n",
        "\n",
        "# Plot the points using matplotlib\n",
        "plt.plot(x, y_sin)\n",
        "plt.plot(x, y_cos)\n",
        "plt.xlabel('x axis label')\n",
        "plt.ylabel('y axis label')\n",
        "plt.title('Sine and Cosine')\n",
        "plt.legend(['Sine', 'Cosine'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui_uyztA0g4y"
      },
      "source": [
        "## Pandas\n",
        "\n",
        "Tutoriales: [1](https://pandas.pydata.org/docs/user_guide/index.html), [2](https://dev.socrata.com/blog/2016/02/01/pandas-and-jupyter-notebook.html), [3](http://nikgrozev.com/2015/12/27/pandas-in-jupyter-quickstart-and-useful-snippets/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOyrsZB10g40"
      },
      "source": [
        "Pandas permite gestionar conjuntos de datos n-dimensionales de diferentes formas, y también conectarlo con matplotlib para hacer gráficas.\n",
        "\n",
        "Los conceptos principales de Pandas son los `Dataframes` y las `Series`. La diferencia entre ambas es que la serie guarda sólo una serie (una columna o una fila, depende de como se quiera interpretar), mientras que un Dataframe guarda estructuras multidimensaionales agregando series.\n",
        "\n",
        "Ambas tienen una (o varias) \"columna fantasma\", que sirve de índice, y que se puede acceder con `d.index` (tanto si `d` es una serie o un dataframe). Si no se especifica un índice, se le añade uno virtual numerando las filas desde cero. Además, los índices pueden ser multidimensionales (por ejemplo, tener un índice por mes y dentro uno por dia de la semana)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cl0Bh4Q-0g44"
      },
      "outputs": [],
      "source": [
        "ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))\n",
        "ts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RQFSUOW0g5A"
      },
      "outputs": [],
      "source": [
        "ts.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEYsgmGG0g5N"
      },
      "outputs": [],
      "source": [
        "ts = ts.cumsum()\n",
        "ts.plot();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJnJN3Mx0g5s"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list('ABCD'))\n",
        "\n",
        "df = df.cumsum()\n",
        "\n",
        "df.plot();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGSFAtW10g5z"
      },
      "source": [
        "Se puede hacer plot también de una columna contra otra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5adevuK0g51",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df3 = pd.DataFrame(np.random.randn(1000, 2), columns=['B', 'C']).cumsum()\n",
        "df3['A'] = pd.Series(list(range(len(df3))))\n",
        "df3.plot(x='A', y='B');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4UceYje0g6A"
      },
      "source": [
        "Valores incompletos. Si no se establecen, se pone a `NaN` (_not a number_)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qc6-3Cdu0g6C"
      },
      "outputs": [],
      "source": [
        "d = {'one' : pd.Series([1., 2., 3.], index=['a', 'b', 'c']),\n",
        "     'two' : pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}\n",
        "df = pd.DataFrame(d)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXZ4QkcK0g6J"
      },
      "source": [
        "`fillna()` permite cambiar el valor de los datos faltantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgsfR4sx0g6K"
      },
      "outputs": [],
      "source": [
        "df.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rM1X2lV0g6R"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(d, index=['d', 'b', 'a'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HanNMeBa0g6b"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(d, index=['d', 'b', 'a'], columns=['two', 'three'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROQ0H5Ny0g6k"
      },
      "source": [
        "A continuación se muestra un ejemplo de uso de Pandas para leer datos y procesarlos en un Dataframe.\n",
        "\n",
        "El primer ejemplo completo carga desde el fichero `swift-question-dates.txt.gz` las fechas de las preguntas en Stackoverflow que contienen el tag \"swift\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPUsDbL00g6m"
      },
      "source": [
        "La función `read_csv` es capaz de leer cualquier fichero CSV y lo convierte en un \"Dataframe\", una estructura de tabla que guarda también los nombres y los tipos de las columnas, así como un índice por el que se identificarán las tablas. La lista incluye la fecha en donde se produjo una pregunta con el tag \"swift\". Como los datos en sí son las fechas, hacemos que la columna de fechas haga a su vez de índice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvDjN15R0g6o"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('https://github.com/dsevilla/bdge/raw/master/intro/swift-question-dates.txt.gz',\n",
        "                 header=None,\n",
        "                 names=['date'],\n",
        "                 compression='gzip',\n",
        "                 parse_dates=['date'],\n",
        "                 index_col='date')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgVSv1lt0g6v",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzPabHwO0g62"
      },
      "source": [
        "De la fecha, extraer sólo la fecha (no la hora, que no nos interesa)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fs9Z3Bd50g68"
      },
      "outputs": [],
      "source": [
        "df.index = df.index.date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwZuo_Dh0g7D"
      },
      "source": [
        "Añadimos una columna de todo \"1\" para especificar que cada pregunta cuenta como 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZYjrZoW0g7F",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df['Count'] = 1\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK9lb7_e0g7L"
      },
      "source": [
        "A los Dataframe de Pandas también se les puede aplicar operaciones de agregación, como `groupby` o `sum`. Finalmente, la funcion `plot()` permite mostrar los datos en un gráfico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHCSo_G60g7M"
      },
      "outputs": [],
      "source": [
        "accum = df.groupby(df.index).sum()\n",
        "accum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUWdf1E30g7S"
      },
      "outputs": [],
      "source": [
        "# Los 30 primeros registros que tengan un número de preguntas mayor que 20 por día.\n",
        "accum = accum[accum.Count > 20][:30]\n",
        "accum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oj-c5bzw0g7Z",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "accum[accum.Count > 30][:30].plot.bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rD7gtAn0g7g"
      },
      "source": [
        "A continuación comprobamos con la página de la Wikipedia cuándo apareció el lenguaje Swift:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlYdNb0I0g7h"
      },
      "outputs": [],
      "source": [
        "!pip install lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEL7lZ4B0g7p"
      },
      "outputs": [],
      "source": [
        "dfwiki = pd.read_html('https://en.wikipedia.org/wiki/Swift_(programming_language)',attrs={'class': 'infobox vevent'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NulSTjML0g70"
      },
      "outputs": [],
      "source": [
        "dfwiki[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVOS7lyB0g77"
      },
      "outputs": [],
      "source": [
        "firstdate = dfwiki[0][1][4]\n",
        "firstdate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrkmQ8O80g8C"
      },
      "outputs": [],
      "source": [
        "from dateutil.parser import parse\n",
        "dt = parse(firstdate.split(';')[0])\n",
        "print (dt.date().isoformat())\n",
        "print (accum.index[0].isoformat())\n",
        "\n",
        "assert dt.date().isoformat() == accum.index[0].isoformat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_QaMNS80g8K"
      },
      "source": [
        "A continuación se muestra cómo ubicar posiciones en un mapa con el paquete `folium`. Se muestra también cómo acceder a distintas posiciones del Dataframe con `iloc`, `loc`, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3M3icJez0g8O"
      },
      "outputs": [],
      "source": [
        "# cargar municipios y mostrarlos en el mapa\n",
        "df = pd.read_csv('https://github.com/dsevilla/bdge/raw/master/intro/municipios-2017.csv.gz',header=0,compression='gzip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUb91na40g8X"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCzxEycf0g8f",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZiOqQHT0g8q"
      },
      "outputs": [],
      "source": [
        "df.iloc[0].NOMBRE_ACTUAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpSPc31P0g8x",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df.loc[:,'NOMBRE_ACTUAL']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bjc7tJwB0g84",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df.iloc[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLhnqWHH0g9D",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df.PROVINCIA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9B0dPbdY0g9L",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df[df.PROVINCIA == 'A Coruña']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFI6VSW80g9R"
      },
      "outputs": [],
      "source": [
        "mula = df[df.NOMBRE_ACTUAL == 'Mula'].iloc[0]\n",
        "mula"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN1qCKKr0g9W"
      },
      "outputs": [],
      "source": [
        "(mula_lat,mula_lon) = (mula.LATITUD_ETRS89, mula.LONGITUD_ETRS89)\n",
        "(mula_lat,mula_lon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6QFogNJ0g9d"
      },
      "source": [
        "El paquete `folium` permite generar mapas de posiciones. El siguiente ejemplo centra un mapa en Mula y pone un marcador con su nombre:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j6EsIXJ0g9e"
      },
      "outputs": [],
      "source": [
        "!pip install folium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-LS4MWO0g9j"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "\n",
        "map = folium.Map(location=[mula_lat, mula_lon],zoom_start=10)\n",
        "folium.Marker(location = [mula_lat, mula_lon], popup=\"{} ({} habitantes)\".format(mula.NOMBRE_ACTUAL,mula.POBLACION_MUNI)).add_to(map)\n",
        "\n",
        "map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdcsqsxU0g9p"
      },
      "source": [
        "## Ejercicio\n",
        "\n",
        "Mostrar con `folium` marcadores para cada pueblo de Murcia. Se pueden usar las funciones `itertuples()` o `iterrows()` de un `Dataframe` para recorrer los elementos del mismo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbOKByplBO7Q"
      },
      "source": [
        "## Datos de Stackoverflow\n",
        "\n",
        "El conjunto de datos de Stackoverflow es un *dump* de datos que cada cierto tiempo realiza el sitio web stackoverflow.com, en particular, la version en español, http://es.stackoverflow.com. El formato de los datos es XML, aunque es muy sencillo de extraer los datos, como veremos a continuación.\n",
        "\n",
        "El contenido original se puede descargar directamente de los diferentes _dumps_ que se realizan de la página de archive.org: https://archive.org/details/stackexchange.\n",
        "\n",
        "Sin embargo, nosotros descargaremos una versión fija previamente descargada para que todos partamos de los mismos datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToYeCqMNBO7R"
      },
      "source": [
        "## Descarga de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQvTT2bOBO7R"
      },
      "source": [
        "En este caso los datos están disponibles en un repositorio git. Se pueden descargar también de la Web, pero se van actualizando. Los descargamos del repositorio git para que todos tengáis los mismos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPXQ7PPZBO7R"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/dsevilla/bd2-data/raw/main/es.stackoverflow/es.stackoverflow.7z.001\n",
        "!wget https://github.com/dsevilla/bd2-data/raw/main/es.stackoverflow/es.stackoverflow.7z.002\n",
        "!wget https://github.com/dsevilla/bd2-data/raw/main/es.stackoverflow/es.stackoverflow.7z.003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA6Z9zk9BO7S"
      },
      "outputs": [],
      "source": [
        "!ls -lh es.stackoverflow.7z*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp81WjeVBO7S"
      },
      "outputs": [],
      "source": [
        "!7zr x es.stackoverflow.7z.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXXtEQUTBO7T"
      },
      "outputs": [],
      "source": [
        "!ls -lh *.xml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54tTnOP8BO7T"
      },
      "source": [
        "## Inspección y procesado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf4Gvz1sBO7T"
      },
      "source": [
        "Podemos inspeccionar los ficheros `.xml` para ver su contenido. Son XML, sí, pero ¿con qué formato?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gnbcXYIBO7U"
      },
      "outputs": [],
      "source": [
        "!head Posts.xml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApKHu1ZgBO7U"
      },
      "source": [
        "Aunque se puede procesar el formato XML, lo que podemos ver es que cada entrada es exactamente una línea que comienza por \"`<row`\", y que contiene un conjunto de atributos en formato \"`atributo=\"valor\"`\". Si lo comprobamos, incluso no existirá ninguna comilla doble **dentro** de otra comilla doble, así que podemos extraer esos pares de forma facil.\n",
        "\n",
        "La siguiente función procesa el fichero XML línea a línea. Primero separa la parte inicial \"`<row`\", y después procesa cada par clave/valor. Lo único que hace es construir el conjunto de atributos que hay en todas las entradas. Como vimos, cada fila contenía atributos diferentes. Queremos obtenerlos todos.\n",
        "\n",
        "La función, en vez de retornar una lista, que ocuparía mucha memoria, retorna un generador, que es una lista (de pares clave-valor, un diccionario) que se va generando a medida que se recorre. Por eso utiliza la construcción `yield` de Python. Esto hace que la función se detenga, y cuando se le pide el siguiente elemento, continúa desde donde se quedó (corrutina)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZN4NYtRKBO7V"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from typing import Iterator\n",
        "\n",
        "def generate_elements_from_lines(filename: str) -> Iterator[dict[str, str]]:\n",
        "\n",
        "  def get_attrs(line: str) -> dict[str, str]:\n",
        "    (_, attrs) = line.split(\"<row \", 2)\n",
        "    return {m.group(1): m.group(2)\n",
        "              for m in re.finditer(r\"(\\w*?)=\\\"(.*?)\\\"\", attrs)}\n",
        "\n",
        "  with open(filename, \"r\") as f:\n",
        "    for line in f:\n",
        "      if \"<row\" in line:\n",
        "        yield get_attrs(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_Pcy0heBO7W"
      },
      "outputs": [],
      "source": [
        "first_row = next(generate_elements_from_lines(\"Posts.xml\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TayEqKvOBO7X"
      },
      "outputs": [],
      "source": [
        "first_row.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ6mVx0FBO7X"
      },
      "source": [
        "Hay que extraer el conjunto de atributos para saber qué columnas tendrá nuestra tabla/CSV o archivo JSON. Recuérdese que las dos primeras filas del archivo XML tenían diferentes atributos. ¿Cómo se haría esto?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Wo1jPDQBO7Y"
      },
      "outputs": [],
      "source": [
        "from typing import Iterator\n",
        "\n",
        "def get_all_attrs(iterator: Iterator[dict[str,str]]) -> set[str]:\n",
        "  all_attrs: set[str] = set()\n",
        "  for row in iterator:\n",
        "    all_attrs.update(row.keys())\n",
        "  return all_attrs\n",
        "\n",
        "all_attrs = get_all_attrs(generate_elements_from_lines(\"Posts.xml\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHBXA4dfBO7Y"
      },
      "source": [
        "El conjunto de atributos es pues:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUUkPSMyBO7Y"
      },
      "outputs": [],
      "source": [
        "all_attrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwLQrOr2BO7Y"
      },
      "source": [
        "Como sabemos que el atributo `Id` va a ser la clave primaria, lo ponemos al principio. Además, generamos una lista, no un conjunto, para que el orden sea conocido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPjVuHr5BO7Z"
      },
      "outputs": [],
      "source": [
        "all_attrs.remove('Id')\n",
        "all_attrs = list(all_attrs)\n",
        "all_attrs.insert(0,'Id')\n",
        "all_attrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjFN1ERBBO7Z"
      },
      "source": [
        "## Escritura del formato CSV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRiaGxTKBO7Z"
      },
      "source": [
        "El formato CSV está especificado en el estándar RFC 4180. https://www.ietf.org/rfc/rfc4180.txt. En general se puede utilizar la biblioteca `csv` de Python 3 y vamos a exportar una línea de cabecera con todos los campos. https://docs.python.org/3/library/csv.html.\n",
        "\n",
        "Tendremos en cuenta que todas las filas tienen que tener las mismas columnas y en el mismo orden dado por `all_attrs`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIzLGoQzBO7Z"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "def write_csv(destfile: str, all_attrs: list[str], iterator: Iterator[dict[str,str]]) -> None:\n",
        "  with open(destfile, 'w') as wf:\n",
        "    cw = csv.writer(wf)\n",
        "\n",
        "    # Escribir la línea de cabecera\n",
        "    cw.writerow(all_attrs)\n",
        "\n",
        "    # Recorrer el iterador\n",
        "    for row in iterator:\n",
        "      row_to_write = [row.get(att, '') for att in all_attrs]\n",
        "      cw.writerow(row_to_write)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YP974wv1BO7a"
      },
      "outputs": [],
      "source": [
        "write_csv('Posts.csv', all_attrs, generate_elements_from_lines('Posts.xml'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZf_dANbBO7a"
      },
      "outputs": [],
      "source": [
        "!head Posts.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSwgPLttBO7a"
      },
      "source": [
        "## Uso de Parquet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lod4l2IBO7b"
      },
      "source": [
        "![Parquet](https://upload.wikimedia.org/wikipedia/commons/4/47/Apache_Parquet_logo.svg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZp2QNDjBO7b"
      },
      "source": [
        "El formato Parquet (https://parquet.apache.org) se ha popularizado recientemente con el uso de fuentes de datos en Internet. En general supone una mejora en todos los aspectos con respecto a CSV y en otros con respecto a JSON y JSON lines.\n",
        "\n",
        "En general, Parquet es un formato de almacenamiento de datos de columnas, que es muy eficiente en términos de espacio y tiempo de acceso. Es un formato binario, pero que se puede leer en muchos lenguajes de programación. Además, permite compresión de datos, lo que lo hace eficiente en tiempo y en espacio.\n",
        "\n",
        "El formato interno del fichero se describe por encima en la siguiente imagen:\n",
        "\n",
        "![Parquet](https://camo.githubusercontent.com/d713741348fd88809ec0809de0a9aea7a6358b04f7d2aace673c9286ee290dfb/68747470733a2f2f7261772e6769746875622e636f6d2f6170616368652f706172717565742d666f726d61742f6d61737465722f646f632f696d616765732f46696c654c61796f75742e676966)\n",
        "\n",
        "El formato Parquet incluye, además de los datos, el esquema de los mismos, lo que hace que se pueda leer sin dar lugar a errores. Esto soluciona el problema que nos encontramos en CSV y JSON, que no incluyen el esquema de los datos.\n",
        "\n",
        "Es incluso fomentado por el Gobierno de España para publicación de los datos: https://datos.gob.es/es/blog/por-que-deberias-de-usar-ficheros-parquet-si-procesas-muchos-datos\n",
        "\n",
        "En Python se puede leer con la biblioteca `pyarrow` (https://arrow.apache.org/docs/python/parquet.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33e2DF_XBO7c"
      },
      "outputs": [],
      "source": [
        "%pip install pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYtTM0kzBO7c"
      },
      "outputs": [],
      "source": [
        "# Write the df dataframe to parquet file\n",
        "df = pd.read_csv('Posts.csv')\n",
        "df.to_parquet('Posts.parquet', compression='snappy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3xgJ8olBO7c"
      },
      "outputs": [],
      "source": [
        "!ls -lh Posts.*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "sesion0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}